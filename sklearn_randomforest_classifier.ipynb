{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy #only sparse matrices allowed\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, max_depth=10).fit(X_train,y_train.ravel())\n",
    "rf_predictions = rf_clf.predict(X_test)\n",
    "rf_accuracy = rf_clf.score(X_test, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8795857988165681"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3518778/how-do-i-read-csv-data-into-a-record-array-in-numpy\n",
    "from numpy import genfromtxt\n",
    "X_test_std = genfromtxt('X_test_std.csv', delimiter=',')\n",
    "X_train_ada_std = genfromtxt('X_train_ada_std.csv', delimiter=',')\n",
    "X_train_std = genfromtxt('X_train_std.csv', delimiter=',')\n",
    "\n",
    "y_test = genfromtxt('y_test.csv', delimiter=',')\n",
    "y_train_ada = genfromtxt('y_train_ada.csv', delimiter=',')\n",
    "y_train = genfromtxt('y_train.csv', delimiter=',')\n",
    "\n",
    "y_test = y_test.astype(int)\n",
    "y_train_ada = y_train_ada.astype(int)\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators = 500, max_depth=10, 87.94%\n",
    "n_estimators = 100, max_depth=10, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2021/06/tune-hyperparameters-with-gridsearchcv/\n",
    "#https://www.mygreatlearning.com/blog/gridsearchcv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [50, 100, 200, 300],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth' : [None, 3, 5, 10],\n",
    "    'max_features' : [None, \"sqrt\", \"log2\"],\n",
    "    'class_weight' : [None, \"balanced\", \"balanced_subsample\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 32\n",
      "n_required_iterations: 32\n",
      "n_possible_iterations: 41\n",
      "min_resources_: 30\n",
      "max_resources_: 47961\n",
      "aggressive_elimination: False\n",
      "factor: 1.2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 288\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaush\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 288 is smaller than n_iter=1598. Running 288 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 240\n",
      "n_resources: 36\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 200\n",
      "n_resources: 43\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 167\n",
      "n_resources: 51\n",
      "Fitting 5 folds for each of 167 candidates, totalling 835 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 140\n",
      "n_resources: 62\n",
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 117\n",
      "n_resources: 74\n",
      "Fitting 5 folds for each of 117 candidates, totalling 585 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 98\n",
      "n_resources: 89\n",
      "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 82\n",
      "n_resources: 107\n",
      "Fitting 5 folds for each of 82 candidates, totalling 410 fits\n",
      "----------\n",
      "iter: 8\n",
      "n_candidates: 69\n",
      "n_resources: 128\n",
      "Fitting 5 folds for each of 69 candidates, totalling 345 fits\n",
      "----------\n",
      "iter: 9\n",
      "n_candidates: 58\n",
      "n_resources: 154\n",
      "Fitting 5 folds for each of 58 candidates, totalling 290 fits\n",
      "----------\n",
      "iter: 10\n",
      "n_candidates: 49\n",
      "n_resources: 185\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "----------\n",
      "iter: 11\n",
      "n_candidates: 41\n",
      "n_resources: 222\n",
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n",
      "----------\n",
      "iter: 12\n",
      "n_candidates: 35\n",
      "n_resources: 267\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "----------\n",
      "iter: 13\n",
      "n_candidates: 30\n",
      "n_resources: 320\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "----------\n",
      "iter: 14\n",
      "n_candidates: 25\n",
      "n_resources: 385\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "----------\n",
      "iter: 15\n",
      "n_candidates: 21\n",
      "n_resources: 462\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "----------\n",
      "iter: 16\n",
      "n_candidates: 18\n",
      "n_resources: 554\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 17\n",
      "n_candidates: 15\n",
      "n_resources: 665\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "----------\n",
      "iter: 18\n",
      "n_candidates: 13\n",
      "n_resources: 798\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "----------\n",
      "iter: 19\n",
      "n_candidates: 11\n",
      "n_resources: 958\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "----------\n",
      "iter: 20\n",
      "n_candidates: 10\n",
      "n_resources: 1150\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "----------\n",
      "iter: 21\n",
      "n_candidates: 9\n",
      "n_resources: 1380\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "----------\n",
      "iter: 22\n",
      "n_candidates: 8\n",
      "n_resources: 1656\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "----------\n",
      "iter: 23\n",
      "n_candidates: 7\n",
      "n_resources: 1987\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 24\n",
      "n_candidates: 6\n",
      "n_resources: 2384\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 25\n",
      "n_candidates: 5\n",
      "n_resources: 2861\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 26\n",
      "n_candidates: 5\n",
      "n_resources: 3434\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 27\n",
      "n_candidates: 5\n",
      "n_resources: 4121\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 28\n",
      "n_candidates: 5\n",
      "n_resources: 4945\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 29\n",
      "n_candidates: 5\n",
      "n_resources: 5934\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 30\n",
      "n_candidates: 5\n",
      "n_resources: 7121\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 31\n",
      "n_candidates: 5\n",
      "n_resources: 8545\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(estimator=RandomForestClassifier(), factor=1.2, n_jobs=-1,\n",
       "                      param_distributions={'class_weight': [None, 'balanced',\n",
       "                                                            'balanced_subsample'],\n",
       "                                           'criterion': ['gini', 'entropy'],\n",
       "                                           'max_depth': [None, 3, 5, 10],\n",
       "                                           'max_features': [None, 'sqrt',\n",
       "                                                            'log2'],\n",
       "                                           'n_estimators': [50, 100, 200, 300]},\n",
       "                      verbose=2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "grid1 = HalvingRandomSearchCV(estimator = rf_clf, param_distributions = param_grid, refit = True, verbose = 2, n_jobs=-1, factor = 1.2)\n",
    "# fitting the model for grid search \n",
    "grid1.fit(X_train_ada_std, y_train_ada.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid1.best_params_) \n",
    "grid_predictions = grid1.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95      2827\n",
      "         1.0       0.42      0.78      0.54       109\n",
      "         2.0       0.84      0.94      0.89       458\n",
      "\n",
      "    accuracy                           0.92      3394\n",
      "   macro avg       0.74      0.88      0.79      3394\n",
      "weighted avg       0.94      0.92      0.93      3394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 32\n",
      "n_required_iterations: 32\n",
      "n_possible_iterations: 36\n",
      "min_resources_: 30\n",
      "max_resources_: 19256\n",
      "aggressive_elimination: False\n",
      "factor: 1.2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 288\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaush\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 288 is smaller than n_iter=641. Running 288 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 240\n",
      "n_resources: 36\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 200\n",
      "n_resources: 43\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 167\n",
      "n_resources: 51\n",
      "Fitting 5 folds for each of 167 candidates, totalling 835 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 140\n",
      "n_resources: 62\n",
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 117\n",
      "n_resources: 74\n",
      "Fitting 5 folds for each of 117 candidates, totalling 585 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 98\n",
      "n_resources: 89\n",
      "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 82\n",
      "n_resources: 107\n",
      "Fitting 5 folds for each of 82 candidates, totalling 410 fits\n",
      "----------\n",
      "iter: 8\n",
      "n_candidates: 69\n",
      "n_resources: 128\n",
      "Fitting 5 folds for each of 69 candidates, totalling 345 fits\n",
      "----------\n",
      "iter: 9\n",
      "n_candidates: 58\n",
      "n_resources: 154\n",
      "Fitting 5 folds for each of 58 candidates, totalling 290 fits\n",
      "----------\n",
      "iter: 10\n",
      "n_candidates: 49\n",
      "n_resources: 185\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "----------\n",
      "iter: 11\n",
      "n_candidates: 41\n",
      "n_resources: 222\n",
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n",
      "----------\n",
      "iter: 12\n",
      "n_candidates: 35\n",
      "n_resources: 267\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "----------\n",
      "iter: 13\n",
      "n_candidates: 30\n",
      "n_resources: 320\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "----------\n",
      "iter: 14\n",
      "n_candidates: 25\n",
      "n_resources: 385\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "----------\n",
      "iter: 15\n",
      "n_candidates: 21\n",
      "n_resources: 462\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "----------\n",
      "iter: 16\n",
      "n_candidates: 18\n",
      "n_resources: 554\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 17\n",
      "n_candidates: 15\n",
      "n_resources: 665\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "----------\n",
      "iter: 18\n",
      "n_candidates: 13\n",
      "n_resources: 798\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "----------\n",
      "iter: 19\n",
      "n_candidates: 11\n",
      "n_resources: 958\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "----------\n",
      "iter: 20\n",
      "n_candidates: 10\n",
      "n_resources: 1150\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "----------\n",
      "iter: 21\n",
      "n_candidates: 9\n",
      "n_resources: 1380\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "----------\n",
      "iter: 22\n",
      "n_candidates: 8\n",
      "n_resources: 1656\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "----------\n",
      "iter: 23\n",
      "n_candidates: 7\n",
      "n_resources: 1987\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 24\n",
      "n_candidates: 6\n",
      "n_resources: 2384\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 25\n",
      "n_candidates: 5\n",
      "n_resources: 2861\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 26\n",
      "n_candidates: 5\n",
      "n_resources: 3434\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 27\n",
      "n_candidates: 5\n",
      "n_resources: 4121\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 28\n",
      "n_candidates: 5\n",
      "n_resources: 4945\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 29\n",
      "n_candidates: 5\n",
      "n_resources: 5934\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 30\n",
      "n_candidates: 5\n",
      "n_resources: 7121\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 31\n",
      "n_candidates: 5\n",
      "n_resources: 8545\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(estimator=RandomForestClassifier(), factor=1.2, n_jobs=-1,\n",
       "                      param_distributions={'class_weight': [None, 'balanced',\n",
       "                                                            'balanced_subsample'],\n",
       "                                           'criterion': ['gini', 'entropy'],\n",
       "                                           'max_depth': [None, 3, 5, 10],\n",
       "                                           'max_features': [None, 'sqrt',\n",
       "                                                            'log2'],\n",
       "                                           'n_estimators': [50, 100, 200, 300]},\n",
       "                      verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "grid = HalvingRandomSearchCV(estimator = rf_clf, param_distributions = param_grid, refit = True, verbose = 2, n_jobs=-1, factor = 1.2)\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train_std, y_train.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      2827\n",
      "         1.0       1.00      0.91      0.95       109\n",
      "         2.0       1.00      0.98      0.99       458\n",
      "\n",
      "    accuracy                           0.99      3394\n",
      "   macro avg       1.00      0.96      0.98      3394\n",
      "weighted avg       0.99      0.99      0.99      3394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features='log2',\n",
       "                       n_estimators=300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a csv for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_year_handler(df_train):\n",
    "    #df_train is the train df loaded from our csv file\n",
    "    #labels are not dealt with here, so keep them in a separate column before calling this\n",
    "    #df_train2 = df_train.drop(columns=[\"S.No\"])\n",
    "    df_train2 = df_train\n",
    "    #df_train2 = df_train\n",
    "    #https://stackoverflow.com/questions/22005911/convert-columns-to-string-in-pandas\n",
    "    #converting to string for the split\n",
    "    df_train2[\"time\"] = df_train2[\"time\"].astype(str)\n",
    "    #expand will return multiple columns with the split strings\n",
    "    split_columns = df_train2[\"time\"].str.split(\"\",expand=True)\n",
    "    year = split_columns[1] + split_columns[2] + split_columns[3] +split_columns[4]\n",
    "    month = split_columns[5] + split_columns[6]\n",
    "    date = split_columns[7] + split_columns[8]\n",
    "    \n",
    "    #converting series to df and renaming the column so we dont end up with a bunch of columns named 0\n",
    "    #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html\n",
    "    year = pd.DataFrame(year)\n",
    "    month = pd.DataFrame(month)\n",
    "    date = pd.DataFrame(date)\n",
    "\n",
    "    year = year.rename(columns={0: \"year\"})\n",
    "    month = month.rename(columns={0: \"month\"})\n",
    "    date = date.rename(columns={0: \"date\"})\n",
    "\n",
    "    #we need to convert the strings back to integers\n",
    "    #https://datatofish.com/string-to-integer-dataframe/\n",
    "    year['year'] = year['year'].astype(int)\n",
    "    month['month'] = month['month'].astype(int)\n",
    "    date['date'] = date['date'].astype(int)\n",
    "    \n",
    "    #adding these back to the original df\n",
    "    df = pd.concat([df_train2, year, month, date], axis = 1)\n",
    "    df = df.drop(columns=[\"time\"])\n",
    "    #df.head()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv(r\"./ift3395-6390-weatherevents/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = df_year_handler(submit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://datascience.stackexchange.com/questions/13567/ways-to-deal-with-longitude-latitude-feature\n",
    "# #https://heartbeat.comet.ml/working-with-geospatial-data-in-machine-learning-ad4097c7228d\n",
    "# #https://stackoverflow.com/questions/14059094/i-want-to-multiply-two-columns-in-a-pandas-dataframe-and-add-the-result-into-a-n\n",
    "# submit_df['cos_lat'] = np.cos(submit_df[['lat']])\n",
    "# submit_df['cos_long'] = np.cos(submit_df[['lon']])\n",
    "# submit_df['sin_lat'] = np.sin(submit_df[['lat']])\n",
    "# submit_df['sin_long'] = np.sin(submit_df[['lon']])\n",
    "\n",
    "# submit_df['x'] = submit_df['cos_lat'] * submit_df['cos_long']\n",
    "# submit_df['y'] = submit_df['cos_lat'] * submit_df['sin_long']\n",
    "# submit_df['z'] = submit_df['sin_lat']\n",
    "\n",
    "# #submit_df = submit_df.drop(columns=['cos_lat','cos_long','sin_lat','sin_long', 'lat', 'lon'])\n",
    "# submit_df = submit_df.drop(columns=['cos_lat','cos_long','sin_lat','sin_long'])\n",
    "\n",
    "\n",
    "# # submit_df[\"x\"] = np.cos(submit_df[['lat']]) * np.cos(submit_df[['lon']])\n",
    "# # submit_df[\"y\"] = np.cos(submit_df[['lat']]) * np.sin(submit_df[['lon']])\n",
    "# # submit_df[\"z\"] = np.sin(submit_df[['lat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = submit_df.drop(columns=[\"S.No\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>TMQ</th>\n",
       "      <th>U850</th>\n",
       "      <th>V850</th>\n",
       "      <th>UBOT</th>\n",
       "      <th>VBOT</th>\n",
       "      <th>QREFHT</th>\n",
       "      <th>PS</th>\n",
       "      <th>PSL</th>\n",
       "      <th>...</th>\n",
       "      <th>T500</th>\n",
       "      <th>PRECT</th>\n",
       "      <th>TS</th>\n",
       "      <th>TREFHT</th>\n",
       "      <th>Z1000</th>\n",
       "      <th>Z200</th>\n",
       "      <th>ZBOT</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>353.1250</td>\n",
       "      <td>22.372244</td>\n",
       "      <td>-1.994936</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>-7.732825</td>\n",
       "      <td>-1.864900</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>102809.6719</td>\n",
       "      <td>102809.6719</td>\n",
       "      <td>...</td>\n",
       "      <td>258.135406</td>\n",
       "      <td>4.060000e-08</td>\n",
       "      <td>290.377930</td>\n",
       "      <td>289.014862</td>\n",
       "      <td>234.634003</td>\n",
       "      <td>12023.84082</td>\n",
       "      <td>63.400764</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>353.4375</td>\n",
       "      <td>21.536032</td>\n",
       "      <td>-2.058918</td>\n",
       "      <td>0.397359</td>\n",
       "      <td>-8.436489</td>\n",
       "      <td>-0.940275</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>102816.6016</td>\n",
       "      <td>102816.6016</td>\n",
       "      <td>...</td>\n",
       "      <td>258.205994</td>\n",
       "      <td>1.670000e-08</td>\n",
       "      <td>290.377228</td>\n",
       "      <td>288.873138</td>\n",
       "      <td>234.982056</td>\n",
       "      <td>12023.83301</td>\n",
       "      <td>63.348942</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>353.7500</td>\n",
       "      <td>20.465317</td>\n",
       "      <td>-2.128485</td>\n",
       "      <td>0.717785</td>\n",
       "      <td>-8.842417</td>\n",
       "      <td>0.152449</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>102827.8594</td>\n",
       "      <td>102827.8594</td>\n",
       "      <td>...</td>\n",
       "      <td>258.242279</td>\n",
       "      <td>1.220000e-08</td>\n",
       "      <td>290.377228</td>\n",
       "      <td>288.641480</td>\n",
       "      <td>235.631378</td>\n",
       "      <td>12025.41113</td>\n",
       "      <td>63.281322</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>354.0625</td>\n",
       "      <td>19.967148</td>\n",
       "      <td>-2.126235</td>\n",
       "      <td>1.123356</td>\n",
       "      <td>-8.773702</td>\n",
       "      <td>1.251795</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>102830.5391</td>\n",
       "      <td>102830.5391</td>\n",
       "      <td>...</td>\n",
       "      <td>258.335113</td>\n",
       "      <td>3.460000e-10</td>\n",
       "      <td>290.441406</td>\n",
       "      <td>288.420074</td>\n",
       "      <td>235.608460</td>\n",
       "      <td>12026.61426</td>\n",
       "      <td>63.216827</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>354.3750</td>\n",
       "      <td>19.598663</td>\n",
       "      <td>-2.053118</td>\n",
       "      <td>1.823581</td>\n",
       "      <td>-8.472447</td>\n",
       "      <td>2.225254</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>102823.8516</td>\n",
       "      <td>102823.8516</td>\n",
       "      <td>...</td>\n",
       "      <td>258.513702</td>\n",
       "      <td>5.920000e-10</td>\n",
       "      <td>290.468903</td>\n",
       "      <td>288.392975</td>\n",
       "      <td>235.004334</td>\n",
       "      <td>12027.29004</td>\n",
       "      <td>63.200485</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>276.5625</td>\n",
       "      <td>51.415295</td>\n",
       "      <td>-1.095974</td>\n",
       "      <td>-8.194263</td>\n",
       "      <td>2.484773</td>\n",
       "      <td>-10.520496</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>100743.8438</td>\n",
       "      <td>100743.8438</td>\n",
       "      <td>...</td>\n",
       "      <td>268.880676</td>\n",
       "      <td>6.870000e-15</td>\n",
       "      <td>302.576569</td>\n",
       "      <td>302.226227</td>\n",
       "      <td>66.832077</td>\n",
       "      <td>12467.79492</td>\n",
       "      <td>66.832077</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>276.8750</td>\n",
       "      <td>52.377407</td>\n",
       "      <td>-0.265653</td>\n",
       "      <td>-8.730537</td>\n",
       "      <td>3.783044</td>\n",
       "      <td>-10.748092</td>\n",
       "      <td>0.021389</td>\n",
       "      <td>100703.5313</td>\n",
       "      <td>100703.5313</td>\n",
       "      <td>...</td>\n",
       "      <td>269.085083</td>\n",
       "      <td>9.240000e-10</td>\n",
       "      <td>302.583557</td>\n",
       "      <td>302.131012</td>\n",
       "      <td>66.827492</td>\n",
       "      <td>12466.41309</td>\n",
       "      <td>66.827492</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>277.1875</td>\n",
       "      <td>54.639217</td>\n",
       "      <td>0.775797</td>\n",
       "      <td>-9.646189</td>\n",
       "      <td>5.087689</td>\n",
       "      <td>-10.786784</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>100673.9844</td>\n",
       "      <td>100673.9844</td>\n",
       "      <td>...</td>\n",
       "      <td>269.305939</td>\n",
       "      <td>5.870000e-08</td>\n",
       "      <td>302.646820</td>\n",
       "      <td>302.032715</td>\n",
       "      <td>66.812981</td>\n",
       "      <td>12467.56934</td>\n",
       "      <td>66.812981</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>277.5000</td>\n",
       "      <td>56.121231</td>\n",
       "      <td>1.813888</td>\n",
       "      <td>-10.849813</td>\n",
       "      <td>6.442380</td>\n",
       "      <td>-10.859090</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>100647.3359</td>\n",
       "      <td>100647.3359</td>\n",
       "      <td>...</td>\n",
       "      <td>269.616638</td>\n",
       "      <td>8.810000e-08</td>\n",
       "      <td>302.646820</td>\n",
       "      <td>302.014435</td>\n",
       "      <td>66.808281</td>\n",
       "      <td>12468.06934</td>\n",
       "      <td>66.808273</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>277.8125</td>\n",
       "      <td>56.888420</td>\n",
       "      <td>2.819084</td>\n",
       "      <td>-12.172881</td>\n",
       "      <td>7.671317</td>\n",
       "      <td>-10.641853</td>\n",
       "      <td>0.022239</td>\n",
       "      <td>100621.3438</td>\n",
       "      <td>100621.3438</td>\n",
       "      <td>...</td>\n",
       "      <td>269.940277</td>\n",
       "      <td>1.110000e-07</td>\n",
       "      <td>302.646820</td>\n",
       "      <td>301.950531</td>\n",
       "      <td>66.808609</td>\n",
       "      <td>12468.50098</td>\n",
       "      <td>66.808151</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7320 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat       lon        TMQ      U850       V850      UBOT  \\\n",
       "0    -31.095176  353.1250  22.372244 -1.994936  -0.002513 -7.732825   \n",
       "1    -31.095176  353.4375  21.536032 -2.058918   0.397359 -8.436489   \n",
       "2    -31.095176  353.7500  20.465317 -2.128485   0.717785 -8.842417   \n",
       "3    -31.095176  354.0625  19.967148 -2.126235   1.123356 -8.773702   \n",
       "4    -31.095176  354.3750  19.598663 -2.053118   1.823581 -8.472447   \n",
       "...         ...       ...        ...       ...        ...       ...   \n",
       "7315  24.054759  276.5625  51.415295 -1.095974  -8.194263  2.484773   \n",
       "7316  24.054759  276.8750  52.377407 -0.265653  -8.730537  3.783044   \n",
       "7317  24.054759  277.1875  54.639217  0.775797  -9.646189  5.087689   \n",
       "7318  24.054759  277.5000  56.121231  1.813888 -10.849813  6.442380   \n",
       "7319  24.054759  277.8125  56.888420  2.819084 -12.172881  7.671317   \n",
       "\n",
       "           VBOT    QREFHT           PS          PSL  ...        T500  \\\n",
       "0     -1.864900  0.008203  102809.6719  102809.6719  ...  258.135406   \n",
       "1     -0.940275  0.007887  102816.6016  102816.6016  ...  258.205994   \n",
       "2      0.152449  0.007695  102827.8594  102827.8594  ...  258.242279   \n",
       "3      1.251795  0.007519  102830.5391  102830.5391  ...  258.335113   \n",
       "4      2.225254  0.007293  102823.8516  102823.8516  ...  258.513702   \n",
       "...         ...       ...          ...          ...  ...         ...   \n",
       "7315 -10.520496  0.020928  100743.8438  100743.8438  ...  268.880676   \n",
       "7316 -10.748092  0.021389  100703.5313  100703.5313  ...  269.085083   \n",
       "7317 -10.786784  0.021745  100673.9844  100673.9844  ...  269.305939   \n",
       "7318 -10.859090  0.021840  100647.3359  100647.3359  ...  269.616638   \n",
       "7319 -10.641853  0.022239  100621.3438  100621.3438  ...  269.940277   \n",
       "\n",
       "             PRECT          TS      TREFHT       Z1000         Z200  \\\n",
       "0     4.060000e-08  290.377930  289.014862  234.634003  12023.84082   \n",
       "1     1.670000e-08  290.377228  288.873138  234.982056  12023.83301   \n",
       "2     1.220000e-08  290.377228  288.641480  235.631378  12025.41113   \n",
       "3     3.460000e-10  290.441406  288.420074  235.608460  12026.61426   \n",
       "4     5.920000e-10  290.468903  288.392975  235.004334  12027.29004   \n",
       "...            ...         ...         ...         ...          ...   \n",
       "7315  6.870000e-15  302.576569  302.226227   66.832077  12467.79492   \n",
       "7316  9.240000e-10  302.583557  302.131012   66.827492  12466.41309   \n",
       "7317  5.870000e-08  302.646820  302.032715   66.812981  12467.56934   \n",
       "7318  8.810000e-08  302.646820  302.014435   66.808281  12468.06934   \n",
       "7319  1.110000e-07  302.646820  301.950531   66.808609  12468.50098   \n",
       "\n",
       "           ZBOT  year  month  date  \n",
       "0     63.400764  2013      9    27  \n",
       "1     63.348942  2013      9    27  \n",
       "2     63.281322  2013      9    27  \n",
       "3     63.216827  2013      9    27  \n",
       "4     63.200485  2013      9    27  \n",
       "...         ...   ...    ...   ...  \n",
       "7315  66.832077  2013      9    16  \n",
       "7316  66.827492  2013      9    16  \n",
       "7317  66.812981  2013      9    16  \n",
       "7318  66.808273  2013      9    16  \n",
       "7319  66.808151  2013      9    16  \n",
       "\n",
       "[7320 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Trying clustering:\n",
    "# from sklearn.cluster import KMeans ,AgglomerativeClustering\n",
    "\n",
    "# # creates 5 clusters using hierarchical clustering.\n",
    "# agc = AgglomerativeClustering(n_clusters = 5, affinity='euclidean', linkage='ward')\n",
    "# submit_df['cluster_lat'] = agc.fit_predict(submit_df[['lat']])\n",
    "\n",
    "# agc = AgglomerativeClustering(n_clusters = 7, affinity='euclidean', linkage='ward')\n",
    "# submit_df['cluster_lon'] = agc.fit_predict(submit_df[['lon']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>TMQ</th>\n",
       "      <th>U850</th>\n",
       "      <th>V850</th>\n",
       "      <th>UBOT</th>\n",
       "      <th>VBOT</th>\n",
       "      <th>QREFHT</th>\n",
       "      <th>PS</th>\n",
       "      <th>PSL</th>\n",
       "      <th>...</th>\n",
       "      <th>T500</th>\n",
       "      <th>PRECT</th>\n",
       "      <th>TS</th>\n",
       "      <th>TREFHT</th>\n",
       "      <th>Z1000</th>\n",
       "      <th>Z200</th>\n",
       "      <th>ZBOT</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>353.1250</td>\n",
       "      <td>22.372244</td>\n",
       "      <td>-1.994936</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>-7.732825</td>\n",
       "      <td>-1.864900</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>102809.6719</td>\n",
       "      <td>102809.6719</td>\n",
       "      <td>...</td>\n",
       "      <td>258.135406</td>\n",
       "      <td>4.060000e-08</td>\n",
       "      <td>290.377930</td>\n",
       "      <td>289.014862</td>\n",
       "      <td>234.634003</td>\n",
       "      <td>12023.84082</td>\n",
       "      <td>63.400764</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>353.4375</td>\n",
       "      <td>21.536032</td>\n",
       "      <td>-2.058918</td>\n",
       "      <td>0.397359</td>\n",
       "      <td>-8.436489</td>\n",
       "      <td>-0.940275</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>102816.6016</td>\n",
       "      <td>102816.6016</td>\n",
       "      <td>...</td>\n",
       "      <td>258.205994</td>\n",
       "      <td>1.670000e-08</td>\n",
       "      <td>290.377228</td>\n",
       "      <td>288.873138</td>\n",
       "      <td>234.982056</td>\n",
       "      <td>12023.83301</td>\n",
       "      <td>63.348942</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>353.7500</td>\n",
       "      <td>20.465317</td>\n",
       "      <td>-2.128485</td>\n",
       "      <td>0.717785</td>\n",
       "      <td>-8.842417</td>\n",
       "      <td>0.152449</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>102827.8594</td>\n",
       "      <td>102827.8594</td>\n",
       "      <td>...</td>\n",
       "      <td>258.242279</td>\n",
       "      <td>1.220000e-08</td>\n",
       "      <td>290.377228</td>\n",
       "      <td>288.641480</td>\n",
       "      <td>235.631378</td>\n",
       "      <td>12025.41113</td>\n",
       "      <td>63.281322</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>354.0625</td>\n",
       "      <td>19.967148</td>\n",
       "      <td>-2.126235</td>\n",
       "      <td>1.123356</td>\n",
       "      <td>-8.773702</td>\n",
       "      <td>1.251795</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>102830.5391</td>\n",
       "      <td>102830.5391</td>\n",
       "      <td>...</td>\n",
       "      <td>258.335113</td>\n",
       "      <td>3.460000e-10</td>\n",
       "      <td>290.441406</td>\n",
       "      <td>288.420074</td>\n",
       "      <td>235.608460</td>\n",
       "      <td>12026.61426</td>\n",
       "      <td>63.216827</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-31.095176</td>\n",
       "      <td>354.3750</td>\n",
       "      <td>19.598663</td>\n",
       "      <td>-2.053118</td>\n",
       "      <td>1.823581</td>\n",
       "      <td>-8.472447</td>\n",
       "      <td>2.225254</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>102823.8516</td>\n",
       "      <td>102823.8516</td>\n",
       "      <td>...</td>\n",
       "      <td>258.513702</td>\n",
       "      <td>5.920000e-10</td>\n",
       "      <td>290.468903</td>\n",
       "      <td>288.392975</td>\n",
       "      <td>235.004334</td>\n",
       "      <td>12027.29004</td>\n",
       "      <td>63.200485</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>276.5625</td>\n",
       "      <td>51.415295</td>\n",
       "      <td>-1.095974</td>\n",
       "      <td>-8.194263</td>\n",
       "      <td>2.484773</td>\n",
       "      <td>-10.520496</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>100743.8438</td>\n",
       "      <td>100743.8438</td>\n",
       "      <td>...</td>\n",
       "      <td>268.880676</td>\n",
       "      <td>6.870000e-15</td>\n",
       "      <td>302.576569</td>\n",
       "      <td>302.226227</td>\n",
       "      <td>66.832077</td>\n",
       "      <td>12467.79492</td>\n",
       "      <td>66.832077</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>276.8750</td>\n",
       "      <td>52.377407</td>\n",
       "      <td>-0.265653</td>\n",
       "      <td>-8.730537</td>\n",
       "      <td>3.783044</td>\n",
       "      <td>-10.748092</td>\n",
       "      <td>0.021389</td>\n",
       "      <td>100703.5313</td>\n",
       "      <td>100703.5313</td>\n",
       "      <td>...</td>\n",
       "      <td>269.085083</td>\n",
       "      <td>9.240000e-10</td>\n",
       "      <td>302.583557</td>\n",
       "      <td>302.131012</td>\n",
       "      <td>66.827492</td>\n",
       "      <td>12466.41309</td>\n",
       "      <td>66.827492</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>277.1875</td>\n",
       "      <td>54.639217</td>\n",
       "      <td>0.775797</td>\n",
       "      <td>-9.646189</td>\n",
       "      <td>5.087689</td>\n",
       "      <td>-10.786784</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>100673.9844</td>\n",
       "      <td>100673.9844</td>\n",
       "      <td>...</td>\n",
       "      <td>269.305939</td>\n",
       "      <td>5.870000e-08</td>\n",
       "      <td>302.646820</td>\n",
       "      <td>302.032715</td>\n",
       "      <td>66.812981</td>\n",
       "      <td>12467.56934</td>\n",
       "      <td>66.812981</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>277.5000</td>\n",
       "      <td>56.121231</td>\n",
       "      <td>1.813888</td>\n",
       "      <td>-10.849813</td>\n",
       "      <td>6.442380</td>\n",
       "      <td>-10.859090</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>100647.3359</td>\n",
       "      <td>100647.3359</td>\n",
       "      <td>...</td>\n",
       "      <td>269.616638</td>\n",
       "      <td>8.810000e-08</td>\n",
       "      <td>302.646820</td>\n",
       "      <td>302.014435</td>\n",
       "      <td>66.808281</td>\n",
       "      <td>12468.06934</td>\n",
       "      <td>66.808273</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>24.054759</td>\n",
       "      <td>277.8125</td>\n",
       "      <td>56.888420</td>\n",
       "      <td>2.819084</td>\n",
       "      <td>-12.172881</td>\n",
       "      <td>7.671317</td>\n",
       "      <td>-10.641853</td>\n",
       "      <td>0.022239</td>\n",
       "      <td>100621.3438</td>\n",
       "      <td>100621.3438</td>\n",
       "      <td>...</td>\n",
       "      <td>269.940277</td>\n",
       "      <td>1.110000e-07</td>\n",
       "      <td>302.646820</td>\n",
       "      <td>301.950531</td>\n",
       "      <td>66.808609</td>\n",
       "      <td>12468.50098</td>\n",
       "      <td>66.808151</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7320 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat       lon        TMQ      U850       V850      UBOT  \\\n",
       "0    -31.095176  353.1250  22.372244 -1.994936  -0.002513 -7.732825   \n",
       "1    -31.095176  353.4375  21.536032 -2.058918   0.397359 -8.436489   \n",
       "2    -31.095176  353.7500  20.465317 -2.128485   0.717785 -8.842417   \n",
       "3    -31.095176  354.0625  19.967148 -2.126235   1.123356 -8.773702   \n",
       "4    -31.095176  354.3750  19.598663 -2.053118   1.823581 -8.472447   \n",
       "...         ...       ...        ...       ...        ...       ...   \n",
       "7315  24.054759  276.5625  51.415295 -1.095974  -8.194263  2.484773   \n",
       "7316  24.054759  276.8750  52.377407 -0.265653  -8.730537  3.783044   \n",
       "7317  24.054759  277.1875  54.639217  0.775797  -9.646189  5.087689   \n",
       "7318  24.054759  277.5000  56.121231  1.813888 -10.849813  6.442380   \n",
       "7319  24.054759  277.8125  56.888420  2.819084 -12.172881  7.671317   \n",
       "\n",
       "           VBOT    QREFHT           PS          PSL  ...        T500  \\\n",
       "0     -1.864900  0.008203  102809.6719  102809.6719  ...  258.135406   \n",
       "1     -0.940275  0.007887  102816.6016  102816.6016  ...  258.205994   \n",
       "2      0.152449  0.007695  102827.8594  102827.8594  ...  258.242279   \n",
       "3      1.251795  0.007519  102830.5391  102830.5391  ...  258.335113   \n",
       "4      2.225254  0.007293  102823.8516  102823.8516  ...  258.513702   \n",
       "...         ...       ...          ...          ...  ...         ...   \n",
       "7315 -10.520496  0.020928  100743.8438  100743.8438  ...  268.880676   \n",
       "7316 -10.748092  0.021389  100703.5313  100703.5313  ...  269.085083   \n",
       "7317 -10.786784  0.021745  100673.9844  100673.9844  ...  269.305939   \n",
       "7318 -10.859090  0.021840  100647.3359  100647.3359  ...  269.616638   \n",
       "7319 -10.641853  0.022239  100621.3438  100621.3438  ...  269.940277   \n",
       "\n",
       "             PRECT          TS      TREFHT       Z1000         Z200  \\\n",
       "0     4.060000e-08  290.377930  289.014862  234.634003  12023.84082   \n",
       "1     1.670000e-08  290.377228  288.873138  234.982056  12023.83301   \n",
       "2     1.220000e-08  290.377228  288.641480  235.631378  12025.41113   \n",
       "3     3.460000e-10  290.441406  288.420074  235.608460  12026.61426   \n",
       "4     5.920000e-10  290.468903  288.392975  235.004334  12027.29004   \n",
       "...            ...         ...         ...         ...          ...   \n",
       "7315  6.870000e-15  302.576569  302.226227   66.832077  12467.79492   \n",
       "7316  9.240000e-10  302.583557  302.131012   66.827492  12466.41309   \n",
       "7317  5.870000e-08  302.646820  302.032715   66.812981  12467.56934   \n",
       "7318  8.810000e-08  302.646820  302.014435   66.808281  12468.06934   \n",
       "7319  1.110000e-07  302.646820  301.950531   66.808609  12468.50098   \n",
       "\n",
       "           ZBOT  year  month  date  \n",
       "0     63.400764  2013      9    27  \n",
       "1     63.348942  2013      9    27  \n",
       "2     63.281322  2013      9    27  \n",
       "3     63.216827  2013      9    27  \n",
       "4     63.200485  2013      9    27  \n",
       "...         ...   ...    ...   ...  \n",
       "7315  66.832077  2013      9    16  \n",
       "7316  66.827492  2013      9    16  \n",
       "7317  66.812981  2013      9    16  \n",
       "7318  66.808273  2013      9    16  \n",
       "7319  66.808151  2013      9    16  \n",
       "\n",
       "[7320 rows x 21 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizer_new(X_train):\n",
    "    df = pd.DataFrame(X_train)\n",
    "    #df = df.drop(columns=[0])\n",
    "    df = (df-df.mean())/df.std()\n",
    "    X_train = df.to_numpy()\n",
    "    num_of_train = X_train.shape[0]\n",
    "    X_train = np.hstack((np.ones((num_of_train,1)),X_train))\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = standardizer_new(submit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.92072966, -0.68148278, ..., -1.15320753,\n",
       "        -0.67696949, -0.61983751],\n",
       "       [ 1.        ,  0.69825665, -0.38632719, ...,  1.05309245,\n",
       "        -0.25935858,  1.21059296],\n",
       "       [ 1.        , -1.18714513,  2.0430303 , ..., -1.64349641,\n",
       "         0.57586323, -1.58888894],\n",
       "       ...,\n",
       "       [ 1.        , -1.18714513,  2.05816648, ...,  1.78852578,\n",
       "         0.15825233,  1.5336101 ],\n",
       "       [ 1.        , -0.78752193, -0.96150218, ..., -0.66291864,\n",
       "         1.41108505,  1.5336101 ],\n",
       "       [ 1.        , -1.18714513,  2.02789412, ...,  1.54338133,\n",
       "        -0.25935858, -0.08147561]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19256, 22)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3394, 22)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19256,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3394,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full_std = np.concatenate((X_train_std, X_test_std), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_train_full_std.csv\", X_train_full_std, delimiter=\",\")\n",
    "np.savetxt(\"y_train_full.csv\", y_train_full, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ada_full_std = np.concatenate((X_train_ada_std, X_test_std), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ada_full = np.concatenate((y_train_ada, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_train_ada_full_std.csv\", X_train_ada_full_std, delimiter=\",\")\n",
    "np.savetxt(\"y_train_ada_full.csv\", y_train_ada_full, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 32\n",
      "n_required_iterations: 32\n",
      "n_possible_iterations: 41\n",
      "min_resources_: 30\n",
      "max_resources_: 51355\n",
      "aggressive_elimination: False\n",
      "factor: 1.2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 288\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaush\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 288 is smaller than n_iter=1711. Running 288 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 240\n",
      "n_resources: 36\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 200\n",
      "n_resources: 43\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 167\n",
      "n_resources: 51\n",
      "Fitting 5 folds for each of 167 candidates, totalling 835 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 140\n",
      "n_resources: 62\n",
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 117\n",
      "n_resources: 74\n",
      "Fitting 5 folds for each of 117 candidates, totalling 585 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 98\n",
      "n_resources: 89\n",
      "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 82\n",
      "n_resources: 107\n",
      "Fitting 5 folds for each of 82 candidates, totalling 410 fits\n",
      "----------\n",
      "iter: 8\n",
      "n_candidates: 69\n",
      "n_resources: 128\n",
      "Fitting 5 folds for each of 69 candidates, totalling 345 fits\n",
      "----------\n",
      "iter: 9\n",
      "n_candidates: 58\n",
      "n_resources: 154\n",
      "Fitting 5 folds for each of 58 candidates, totalling 290 fits\n",
      "----------\n",
      "iter: 10\n",
      "n_candidates: 49\n",
      "n_resources: 185\n",
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "----------\n",
      "iter: 11\n",
      "n_candidates: 41\n",
      "n_resources: 222\n",
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n",
      "----------\n",
      "iter: 12\n",
      "n_candidates: 35\n",
      "n_resources: 267\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "----------\n",
      "iter: 13\n",
      "n_candidates: 30\n",
      "n_resources: 320\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "----------\n",
      "iter: 14\n",
      "n_candidates: 25\n",
      "n_resources: 385\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "----------\n",
      "iter: 15\n",
      "n_candidates: 21\n",
      "n_resources: 462\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "----------\n",
      "iter: 16\n",
      "n_candidates: 18\n",
      "n_resources: 554\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 17\n",
      "n_candidates: 15\n",
      "n_resources: 665\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "----------\n",
      "iter: 18\n",
      "n_candidates: 13\n",
      "n_resources: 798\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "----------\n",
      "iter: 19\n",
      "n_candidates: 11\n",
      "n_resources: 958\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "----------\n",
      "iter: 20\n",
      "n_candidates: 10\n",
      "n_resources: 1150\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "----------\n",
      "iter: 21\n",
      "n_candidates: 9\n",
      "n_resources: 1380\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "----------\n",
      "iter: 22\n",
      "n_candidates: 8\n",
      "n_resources: 1656\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "----------\n",
      "iter: 23\n",
      "n_candidates: 7\n",
      "n_resources: 1987\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 24\n",
      "n_candidates: 6\n",
      "n_resources: 2384\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 25\n",
      "n_candidates: 5\n",
      "n_resources: 2861\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 26\n",
      "n_candidates: 5\n",
      "n_resources: 3434\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 27\n",
      "n_candidates: 5\n",
      "n_resources: 4121\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 28\n",
      "n_candidates: 5\n",
      "n_resources: 4945\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 29\n",
      "n_candidates: 5\n",
      "n_resources: 5934\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 30\n",
      "n_candidates: 5\n",
      "n_resources: 7121\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 31\n",
      "n_candidates: 5\n",
      "n_resources: 8545\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(estimator=RandomForestClassifier(), factor=1.2, n_jobs=-1,\n",
       "                      param_distributions={'class_weight': [None, 'balanced',\n",
       "                                                            'balanced_subsample'],\n",
       "                                           'criterion': ['gini', 'entropy'],\n",
       "                                           'max_depth': [None, 3, 5, 10],\n",
       "                                           'max_features': [None, 'sqrt',\n",
       "                                                            'log2'],\n",
       "                                           'n_estimators': [50, 100, 200, 300]},\n",
       "                      verbose=2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "grid1 = HalvingRandomSearchCV(estimator = rf_clf, param_distributions = param_grid, refit = True, verbose = 2, n_jobs=-1, factor = 1.2)\n",
    "# fitting the model for grid search \n",
    "grid1.fit(X_train_ada_full_std, y_train_ada_full.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid1.best_params_) \n",
    "#grid_predictions = grid1.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_submit = grid1.predict(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kite.com/python/answers/how-to-create-pandas-dataframe-from-a-numpy-array-in-python\n",
    "predictions_df = pd.DataFrame(data=predictions_submit,columns=[\"LABELS\"]).astype(int)\n",
    "#https://stackoverflow.com/questions/18022845/pandas-index-column-title-or-name\n",
    "predictions_df.index.name = \"S.No\"\n",
    "predictions_df.to_csv(r\"./ift3395-6390-weatherevents/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
