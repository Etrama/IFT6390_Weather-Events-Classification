{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy #only sparse matrices allowed\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:27:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "xgb_clf = XGBClassifier().fit(X_train,y_train.ravel())\n",
    "xgb_predictions = xgb_clf.predict(X_test)\n",
    "xgb_accuracy = xgb_clf.score(X_test, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807692307692307"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3518778/how-do-i-read-csv-data-into-a-record-array-in-numpy\n",
    "from numpy import genfromtxt\n",
    "X_test_std = genfromtxt('X_test_std.csv', delimiter=',')\n",
    "X_train_ada_std = genfromtxt('X_train_ada_std.csv', delimiter=',')\n",
    "X_train_std = genfromtxt('X_train_std.csv', delimiter=',')\n",
    "\n",
    "y_test = genfromtxt('y_test.csv', delimiter=',')\n",
    "y_train_ada = genfromtxt('y_train_ada.csv', delimiter=',')\n",
    "y_train = genfromtxt('y_train.csv', delimiter=',')\n",
    "\n",
    "y_test = y_test.astype(int)\n",
    "y_train_ada = y_train_ada.astype(int)\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2021/06/tune-hyperparameters-with-gridsearchcv/\n",
    "#https://www.mygreatlearning.com/blog/gridsearchcv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_tree = {\n",
    "    'booster' : ['gbtree'],\n",
    "    'use_label_encoder' : [False],\n",
    "    'eta' : [0.1, 0.3, 0.5, 1.0],\n",
    "    'max_depth' : [3, 6, 9, 15],\n",
    "    'subsample' : [0.5, 1.0],\n",
    "    'max_delta_step' : [0, 1, 2, 4, 8],#might help with imbaanced classes\n",
    "    #'lambda' : [0.8, 1.0, 1.2, 1.4],\n",
    "    'alpha': [0, 0.2, 0.4, 1.0]  \n",
    "}\n",
    "\n",
    "param_grid_linear1 = {\n",
    "    'booster' : ['gblinear'],\n",
    "    'use_label_encoder' : [False],\n",
    "    'alpha': [0, 0.2, 0.4, 1.0],\n",
    "    'lambda' : [0, 0.2, 0.4],\n",
    "    'udpater' : ['shotgun'],\n",
    "    'feature_selector' : ['cyclic', 'shuffle'],\n",
    "    'use_label_encoder' : [False],\n",
    "}\n",
    "\n",
    "\n",
    "param_grid_dart = {\n",
    "    'booster' : ['dart'],\n",
    "    'use_label_encoder' : [False],\n",
    "    'sample_type' : ['uniform', 'weighted'],\n",
    "    'normalize_type' : ['tree', 'forest'],\n",
    "    'rate_drop' : [0.0, 0.2, 0.4],\n",
    "    'one_drop' : [0, 1],\n",
    "    'skip_drop' : [0.0, 0.2],  \n",
    "    'use_label_encoder' : [False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 15\n",
      "n_required_iterations: 15\n",
      "n_possible_iterations: 29\n",
      "min_resources_: 30\n",
      "max_resources_: 47961\n",
      "aggressive_elimination: False\n",
      "factor: 1.3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 48\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaush\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 48 is smaller than n_iter=1598. Running 48 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 37\n",
      "n_resources: 39\n",
      "Fitting 5 folds for each of 37 candidates, totalling 185 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 29\n",
      "n_resources: 50\n",
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 23\n",
      "n_resources: 65\n",
      "Fitting 5 folds for each of 23 candidates, totalling 115 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 18\n",
      "n_resources: 85\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 14\n",
      "n_resources: 111\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 11\n",
      "n_resources: 144\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 9\n",
      "n_resources: 188\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "----------\n",
      "iter: 8\n",
      "n_candidates: 7\n",
      "n_resources: 244\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 9\n",
      "n_candidates: 6\n",
      "n_resources: 318\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 10\n",
      "n_candidates: 5\n",
      "n_resources: 413\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "----------\n",
      "iter: 11\n",
      "n_candidates: 4\n",
      "n_resources: 537\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 12\n",
      "n_candidates: 4\n",
      "n_resources: 698\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 13\n",
      "n_candidates: 4\n",
      "n_resources: 908\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 14\n",
      "n_candidates: 4\n",
      "n_resources: 1181\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[15:01:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingRandomSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None, gamma=None,\n",
       "                                              gpu_id=None,\n",
       "                                              importance_type='gain',\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_...\n",
       "                                              random_state=None, reg_alpha=None,\n",
       "                                              reg_lambda=None,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None),\n",
       "                      factor=1.3, n_jobs=-1,\n",
       "                      param_distributions={'booster': ['dart'],\n",
       "                                           'normalize_type': ['tree', 'forest'],\n",
       "                                           'one_drop': [0, 1],\n",
       "                                           'rate_drop': [0.0, 0.2, 0.4],\n",
       "                                           'sample_type': ['uniform',\n",
       "                                                           'weighted'],\n",
       "                                           'skip_drop': [0.0, 0.2],\n",
       "                                           'use_label_encoder': [False]},\n",
       "                      verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "grid = HalvingRandomSearchCV(estimator = xgb_clf, param_distributions = param_grid_dart, refit = True, verbose = 2, n_jobs=-1, factor = 1.3)\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train_ada_std, y_train_ada.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_label_encoder': False, 'skip_drop': 0.2, 'sample_type': 'uniform', 'rate_drop': 0.0, 'one_drop': 0, 'normalize_type': 'forest', 'booster': 'dart'}\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85      2827\n",
      "           1       0.26      0.96      0.41       109\n",
      "           2       0.52      0.97      0.68       458\n",
      "\n",
      "    accuracy                           0.79      3394\n",
      "   macro avg       0.59      0.89      0.65      3394\n",
      "weighted avg       0.90      0.79      0.82      3394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a csv for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_df_submit = df_standardizer(submit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit_np = standardized_df_submit.to_numpy()\n",
    "num_submit = df_submit_np.shape[0]\n",
    "X_submit = np.hstack((np.ones((num_submit,1)),df_submit_np))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7320, 22)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_submit = lightgbm_clf.predict(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kite.com/python/answers/how-to-create-pandas-dataframe-from-a-numpy-array-in-python\n",
    "predictions_df = pd.DataFrame(data=predictions_submit,columns=[\"LABELS\"]).astype(int)\n",
    "#https://stackoverflow.com/questions/18022845/pandas-index-column-title-or-name\n",
    "predictions_df.index.name = \"S.No\"\n",
    "predictions_df.to_csv(r\"./ift3395-6390-weatherevents/submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
